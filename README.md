# Chat With PDF [Demo Here](https://www.youtube.com/watch?v=crji8FnIFAY)

A desktop application that enables interactive conversations with PDF documents using local Large Language Models (LLMs). Built with Python and Flet, this application provides a complete solution for document analysis and questioning while maintaining full privacy through local AI processing.

## Features

### ğŸ–¥ï¸ Desktop GUI Application
- **Modern Interface**: Built with Flet for cross-platform compatibility
- **Split-Pane Design**: PDF viewer alongside interactive chat interface
- **Real-Time PDF Rendering**: Convert PDF pages to images for in-app viewing
- **Resizable Interface**: Drag-to-resize sidebar with smooth animations
- **Loading Indicators**: Progressive loading animations for better UX

### ğŸ¤– Local AI Integration
- **Local LLM backend**: Model Runner from Docker with Gemma3n
- **Streaming Responses**: Real-time chat with response timing information
- **RAG Pipeline**: Retrieval-Augmented Generation using LlamaIndex
- **Local Embeddings**: Custom GGUF embedding model support
- **Privacy-First**: All processing happens locally, no cloud dependencies

### ğŸ“„ PDF Processing
- **PyMuPDF Integration**: Robust PDF loading and page conversion
- **Image Rendering**: High-quality page rendering at 150 DPI
- **File Management**: Automatic cleanup and organization of processed files
- **Multi-Page Support**: Handle documents of any size

### ğŸ”§ Advanced Architecture
- **Custom Integrations**: Purpose-built LlamaIndex extensions
- **Service Layer**: Clean separation between UI and AI components
- **Agent System**: Intelligent document querying with context awareness
- **Tool Calling**: Agent has access to two tools - rag_query and goto_page

## Architecture

### Frontend (Flet-based GUI)
- **Framework**: Python-based Flet framework for cross-platform desktop apps
- **Layout**: Responsive split-pane design with PDF viewer and chat sidebar
- **Components**:
  - File picker with PDF upload support
  - Real-time page rendering with scroll support
  - Chat interface with styled message bubbles
  - Resizable sidebar with drag functionality
  - Menu bar with File and Chat options
  - Progress animations and loading indicators

### Backend Service Layer
- **PDFService**: Handles file operations, PDF processing, and AI coordination
- **File Management**: Automatic organization of storage/data and storage/ui directories
- **PDF Processing**: PyMuPDF integration for document loading and page conversion
- **Image Generation**: Convert PDF pages to PNG images for UI display

### AI Agent System
- **PDFAgent**: Implements RAG pipeline for document querying
- **LlamaIndex Integration**: Vector indexing and query engine
- **Streaming**: Real-time response generation with timing metrics

### Custom Integrations
- **LlamaCppEmbedding**: Custom embedding model for GGUF format support
- **DockerLLM**: RESTful API integration with Docker Model Runner
- **Multi-Modal Support**: Text embeddings with future image capability

## Technical Stack

### Core Dependencies
- **UI Framework**: Flet 0.28.2
- **PDF Processing**: PyMuPDF, PDFPlumber
- **AI/ML Stack**: LlamaIndex, llama-cpp-python
- **Models**: Local GGUF models, Ollama integration
- **Environment**: Virtual environment with Python 3.9+

### Supported Platforms
- **macOS**: Native support with Metal acceleration
- **Windows**: Full compatibility with Windows-specific optimizations
- **Linux**: Cross-platform support

## Project Structure

```
chat-with-pdf/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ frontend/          # Flet UI components and styles
â”‚   â”‚   â”œâ”€â”€ main.py       # Main application entry point
â”‚   â”‚   â””â”€â”€ styles.py     # UI styling and layout definitions
â”‚   â”œâ”€â”€ backend/          # Core business logic
â”‚   â”‚   â”œâ”€â”€ service.py    # PDF processing and file management
â”‚   â”‚   â””â”€â”€ agent.py      # AI agent and RAG implementation
â”‚   â””â”€â”€ assets/           # Application assets
â”œâ”€â”€ llamaindex_utils/     # Custom LlamaIndex integrations
â”‚   â”œâ”€â”€ integrations.py  # LlamaCppEmbedding and DockerLLM
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ local_models/         # Local AI models storage
â”‚   â”œâ”€â”€ embed/           # Embedding models (GGUF)
â”‚   â”œâ”€â”€ text/            # Chat models
â”‚   â””â”€â”€ vision/          # Future vision models
â”œâ”€â”€ storage/             # Runtime data
â”‚   â”œâ”€â”€ data/            # Document index storage
â”‚   â”œâ”€â”€ temp/            # Temporary processing files
â”‚   â””â”€â”€ ui/              # PDF page images for UI
â”œâ”€â”€ myvenv/              # Virtual environment
â”œâ”€â”€ pyproject.toml       # Project configuration
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ .env                 # Environment variables
```

## Configuration

### Environment Variables (.env)
```env
DATA_PATH=storage/data                    # Document index storage
UI_PATH=storage/ui                        # PDF page images
EMBED_MODEL_PATH=./local_models/embed/... # Embedding model path
DOCKER_MODEL_RUNNER_URL=http://localhost:12434  # Docker backend URL
LOGO_PATH=src/assets/logo.png            # Application logo
```

### Model Configuration
- **Default Backend**: Docker Model Runner with Gemma3n
- **Embedding Model**: Nomic Embed Text v2 MOE (Q8_0 GGUF)

For detailed packaging instructions, refer to the [Flet Documentation](https://flet.dev/docs/publish/).

## Troubleshooting

### Common Issues
- **Model Loading**: Ensure embedding model is present in `local_models/embed/`
- **Docker Backend**: Docker Desktop must be running for Docker Model Runner
- **File Permissions**: Check write permissions for `storage/` directories
- **Memory Usage**: Large PDFs may require significant RAM for processing

### Performance Tips
- **Model Selection**: Choose appropriate model size for your hardware
- **PDF Optimization**: Smaller PDFs process faster and use less memory
- **Backend Selection**: Try different LLM backends for optimal performance

## Contributing

This project uses a modular architecture that makes it easy to:
- Add new LLM backends
- Implement additional file formats
- Enhance UI components
- Integrate new AI models

## License

This is a portfolio project developed to enhance software development and AI skills. 

---

**Chat With PDF** - Bringing AI-powered document analysis to your desktop with complete privacy and local processing.
